{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Standard Package Imports\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import sparse\n",
    "from numpy.random import default_rng\n",
    "\n",
    "# Custom Imports\n",
    "import pgmax.contrib.interface.node_classes as node_classes\n",
    "import pgmax.contrib.mpbp.mp_belief_prop_jax_orig as mp_belief_prop_jax_orig"
   ]
  },
  {
   "source": [
    "## Setting up Image and Factor Graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for rng\n",
    "rng = default_rng(23)\n",
    "\n",
    "# Create a synthetic depth image for testing purposes\n",
    "im_size = 96\n",
    "depth_img = 5.0 * np.ones((im_size, im_size))\n",
    "depth_img[np.tril_indices(im_size, 0)] = 1.0 # This sets the lower triangle of the image to 1's \n",
    "depth_img = gaussian_filter(depth_img, sigma=0.5) # Filter the depth image for realistic noise simulation?\n",
    "labels_img = np.zeros((im_size, im_size), dtype=np.int32)\n",
    "labels_img[np.tril_indices(im_size, 0)] = 1\n",
    "\n",
    "# Plot the depth and label images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(depth_img)\n",
    "ax[0].set_title('Depth Observation Image (yellow is higher depth than purple)')\n",
    "ax[1].imshow(labels_img)\n",
    "ax[1].set_title('Label Image (yellow is higher depth than purple)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = depth_img.shape\n",
    "# Compute dI/dx (horizontal derivative)\n",
    "horizontal_depth_differences = depth_img[:-1] - depth_img[1:]\n",
    "# Compute dI/dy (vertical derivative)\n",
    "vertical_depth_differences = depth_img[:, :-1] - depth_img[:, 1:]\n",
    "\n",
    "# The below code block assigns values for the orientation of every horizontally-oriented cut\n",
    "# It creates a matrix to represent each of the horizontal cuts in the image graph (there will be (M-1, N) possible cuts)\n",
    "# Assigning a cut of 1 points to the left and a cut of 2 points to the right. A cut of 0 indicates an 'off; state\n",
    "horizontal_oriented_cuts = np.zeros((M - 1, N))\n",
    "horizontal_oriented_cuts[horizontal_depth_differences < 0] = 1\n",
    "horizontal_oriented_cuts[horizontal_depth_differences > 0] = 2\n",
    "\n",
    "# The below code block assigns values for the orientation of every vertically-oriented cut\n",
    "# It creates a matrix to represent each of the vertical cuts in the image graph (there will be (M-1, N) possible cuts)\n",
    "# Assigning a cut of 1 points up and a cut of 2 points down. A cut of 0 indicates an 'off' state\n",
    "vertical_oriented_cuts = np.zeros((M, N - 1))\n",
    "vertical_oriented_cuts[vertical_depth_differences < 0] = 1\n",
    "vertical_oriented_cuts[vertical_depth_differences > 0] = 2\n",
    "gt_has_cuts = np.zeros((2, M, N))\n",
    "gt_has_cuts[0, :-1] = horizontal_oriented_cuts\n",
    "gt_has_cuts[1, :, :-1] = vertical_oriented_cuts\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(horizontal_oriented_cuts)\n",
    "ax[1].imshow(vertical_oriented_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to easily generate a list of valid configurations for a given suppression diameter\n",
    "def create_valid_suppression_config_arr(suppression_diameter):\n",
    "    valid_suppressions_list = []\n",
    "    base_list = [0] * suppression_diameter\n",
    "    valid_suppressions_list.append(base_list)\n",
    "    for idx in range(suppression_diameter):\n",
    "        new_valid_list1 = base_list[:]\n",
    "        new_valid_list2 = base_list[:]\n",
    "        new_valid_list1[idx] = 1\n",
    "        new_valid_list2[idx] = 2\n",
    "        valid_suppressions_list.append(new_valid_list1)\n",
    "        valid_suppressions_list.append(new_valid_list2)\n",
    "    return np.array(valid_suppressions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the Factor Graph by instantiating Factor and Variable Nodes and writing out neighbors\n",
    "factors_dict = {}\n",
    "# The Factors for the laterals model will form a (M-1) x (N-1) grid\n",
    "for row in range(M - 1):\n",
    "    for col in range(N - 1):\n",
    "        factor_name = f\"F{row},{col}\"\n",
    "        curr_factor = node_classes.FactorNode(factor_name)\n",
    "        factors_dict[factor_name] = curr_factor\n",
    "\n",
    "vars_list = []\n",
    "vars_dict = {}\n",
    "factors_neighbors_dict = {}\n",
    "NUM_VAR_STATES = 3\n",
    "# Now that we have factors in place, we can create variables and assign neighbor relations\n",
    "# NOTE: The naming scheme for variables is not thorough. For instance, V1,1,down should be the same node as\n",
    "# V2,1,up however this is not the case because a variable can only have one name...\n",
    "for row in range(M - 1):\n",
    "    for col in range(N - 1):\n",
    "        if col == 0:\n",
    "            left_var_name = f\"V{row},{col},left\"\n",
    "            left_var = node_classes.VariableNode(left_var_name, NUM_VAR_STATES)\n",
    "            left_var.add_neighbor(factors_dict[f\"F{row},{col}\"])\n",
    "            factors_neighbors_dict[f\"F{row},{col}\"] = factors_neighbors_dict.get(\n",
    "                f\"F{row},{col}\", []\n",
    "            ) + [left_var]\n",
    "            vars_list.append(left_var)\n",
    "            vars_dict[left_var_name] = left_var\n",
    "\n",
    "        if row == 0:\n",
    "            up_var_name = f\"V{row},{col},up\"\n",
    "            up_var = node_classes.VariableNode(up_var_name, NUM_VAR_STATES)\n",
    "            up_var.add_neighbor(factors_dict[f\"F{row},{col}\"])\n",
    "            factors_neighbors_dict[f\"F{row},{col}\"] = factors_neighbors_dict.get(\n",
    "                f\"F{row},{col}\", []\n",
    "            ) + [up_var]\n",
    "            vars_list.append(up_var)\n",
    "            vars_dict[up_var_name] = up_var\n",
    "\n",
    "        right_var_name = f\"V{row},{col},right\"\n",
    "        right_var = node_classes.VariableNode(right_var_name, NUM_VAR_STATES)\n",
    "        right_var.add_neighbor(factors_dict[f\"F{row},{col}\"])\n",
    "        factors_neighbors_dict[f\"F{row},{col}\"] = factors_neighbors_dict.get(\n",
    "            f\"F{row},{col}\", []\n",
    "        ) + [right_var]\n",
    "        # If the right_var is not at the last column, it will also have another factor neighbor\n",
    "        if col != N - 2:\n",
    "            right_var.add_neighbor(factors_dict[f\"F{row},{col+1}\"])\n",
    "            factors_neighbors_dict[f\"F{row},{col+1}\"] = factors_neighbors_dict.get(\n",
    "                f\"F{row},{col+1}\", []\n",
    "            ) + [right_var]\n",
    "        vars_list.append(right_var)\n",
    "        vars_dict[right_var_name] = right_var\n",
    "\n",
    "        down_var_name = f\"V{row},{col},down\"\n",
    "        down_var = node_classes.VariableNode(down_var_name, NUM_VAR_STATES)\n",
    "        down_var.add_neighbor(factors_dict[f\"F{row},{col}\"])\n",
    "        factors_neighbors_dict[f\"F{row},{col}\"] = factors_neighbors_dict.get(\n",
    "            f\"F{row},{col}\", []\n",
    "        ) + [down_var]\n",
    "        # If the down_var is not at the last row, it will also have another factor neighbor\n",
    "        if row != M - 2:\n",
    "            down_var.add_neighbor(factors_dict[f\"F{row+1},{col}\"])\n",
    "            factors_neighbors_dict[f\"F{row+1},{col}\"] = factors_neighbors_dict.get(\n",
    "                f\"F{row+1},{col}\", []\n",
    "            ) + [down_var]\n",
    "        vars_list.append(down_var)\n",
    "        vars_dict[down_var_name] = down_var\n",
    "\n",
    "        # To make sure the factor neighbors are ALWAYS in the same order (i.e [left_var, up_var, right_var, down_var]),\n",
    "        # we need to perform a swap on factor_neighbors_dict for all rows except the first in the graph\n",
    "        if row != 0:\n",
    "            neighbors_list = factors_neighbors_dict[f\"F{row},{col}\"]\n",
    "            zero_index_neighbor = neighbors_list[0]\n",
    "            neighbors_list[0] = neighbors_list[1]\n",
    "            neighbors_list[1] = zero_index_neighbor\n",
    "            factors_neighbors_dict[f\"F{row},{col}\"] = neighbors_list\n",
    "\n",
    "# Now that we have all the variables and know their connections with the existing factors are correct, we can define the suppression factors\n",
    "# as well as their connections\n",
    "SUPPRESSION_DIAMETER = 9\n",
    "suppression_factors_list = []\n",
    "# Add factors for all the vertical variables\n",
    "row = 0\n",
    "up_or_down = \"up\"\n",
    "while row < M - 1:\n",
    "    vertical_vars_list = [\n",
    "        vars_dict[f\"V{row},{col},\" + up_or_down] for col in range(SUPPRESSION_DIAMETER)\n",
    "    ]\n",
    "\n",
    "    for stride in range(N - SUPPRESSION_DIAMETER):\n",
    "        if row == 0 and up_or_down == \"up\":\n",
    "            curr_vert_supp_factor = node_classes.FactorNode(f\"FSV0,{stride}\")\n",
    "        else:\n",
    "            curr_vert_supp_factor = node_classes.FactorNode(f\"FSV{row+1},{stride}\")\n",
    "        for vert_var in vertical_vars_list:\n",
    "            vert_var.add_neighbor(curr_vert_supp_factor)\n",
    "        curr_vert_supp_factor.set_neighbors(vertical_vars_list)\n",
    "        suppression_factors_list.append(curr_vert_supp_factor)\n",
    "        # IMPORTANT: This below line is necessary because otherwise, the underlying list will get modified\n",
    "        # and cause the Factor's neighbors to change!\n",
    "        vertical_vars_list = vertical_vars_list[:]\n",
    "\n",
    "        # Unless we're on the last column, where we can't slide to the right, remove the first element and \n",
    "        # add another one to effectively slide the suppression to the right\n",
    "        if stride < N - SUPPRESSION_DIAMETER - 1:\n",
    "            _ = vertical_vars_list.pop(0)\n",
    "            vertical_vars_list.append(\n",
    "                vars_dict[f\"V{row},{stride + SUPPRESSION_DIAMETER},\" + up_or_down]\n",
    "            )\n",
    "\n",
    "    # If the loop just went thru 'up' vars for row 0, make it go down\n",
    "    if row == 0 and up_or_down == \"up\":\n",
    "        up_or_down = \"down\"\n",
    "    else:\n",
    "        row += 1\n",
    "\n",
    "# Add factors for all the horizontal variables\n",
    "col = 0\n",
    "left_or_right = \"left\"\n",
    "while col < N - 1:\n",
    "    horizontal_vars_list = [\n",
    "        vars_dict[f\"V{row},{col},\" + left_or_right]\n",
    "        for row in range(SUPPRESSION_DIAMETER)\n",
    "    ]\n",
    "\n",
    "    for stride in range(M - SUPPRESSION_DIAMETER):\n",
    "        if col == 0 and left_or_right == \"left\":\n",
    "            curr_horz_supp_factor = node_classes.FactorNode(f\"FSH0,{stride}\")\n",
    "        else:\n",
    "            curr_horz_supp_factor = node_classes.FactorNode(f\"FSH{col+1},{stride}\")\n",
    "        for horz_var in horizontal_vars_list:\n",
    "            horz_var.add_neighbor(curr_horz_supp_factor)\n",
    "        curr_horz_supp_factor.set_neighbors(horizontal_vars_list)\n",
    "        suppression_factors_list.append(curr_horz_supp_factor)\n",
    "        # IMPORTANT: This below line is necessary because otherwise, the underlying list will get modified\n",
    "        # and cause the Factor's neighbors to change!\n",
    "        horizontal_vars_list = horizontal_vars_list[:]\n",
    "        \n",
    "        # Unless we're on the last column, where we can't slide down, remove the first element and \n",
    "        # add another one to effectively slide the suppression down\n",
    "        if stride < M - 1 - SUPPRESSION_DIAMETER:\n",
    "            _ = horizontal_vars_list.pop(0)\n",
    "            horizontal_vars_list.append(\n",
    "                vars_dict[f\"V{stride + SUPPRESSION_DIAMETER},{col},\" + left_or_right]\n",
    "            )\n",
    "\n",
    "    # If the loop just went thru 'up' vars for row 0, make it go down\n",
    "    if col == 0 and left_or_right == \"left\":\n",
    "        left_or_right = \"right\"\n",
    "    else:\n",
    "        col += 1\n",
    "\n",
    "# Now, we specify the valid configurations for all the suppression factors\n",
    "valid_suppressions_arr = create_valid_suppression_config_arr(SUPPRESSION_DIAMETER)\n",
    "for supp_factor in suppression_factors_list:\n",
    "    supp_factor.set_valid_configs(valid_suppressions_arr)\n",
    "\n",
    "# Now, we need to specify all the valid configurations for the non-suppression factors\n",
    "\"\"\"\n",
    "      1v\n",
    "0h  factor  2h\n",
    "      3v\n",
    "\"\"\"\n",
    "valid_configs = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 0, 1, 0],\n",
    "        [2, 0, 2, 0],\n",
    "        [0, 0, 1, 1],\n",
    "        [0, 0, 2, 2],\n",
    "        [2, 0, 0, 1],\n",
    "        [1, 0, 0, 2],\n",
    "        [1, 0, 1, 1],\n",
    "        [2, 0, 2, 1],\n",
    "        [1, 0, 1, 2],\n",
    "        [2, 0, 2, 2],\n",
    "        [0, 1, 0, 1],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 1, 2, 0],\n",
    "        [1, 1, 0, 1],\n",
    "        [2, 1, 0, 1],\n",
    "        [0, 1, 1, 1],\n",
    "        [0, 1, 2, 1],\n",
    "        [1, 1, 1, 0],\n",
    "        [2, 1, 2, 0],\n",
    "        [0, 2, 0, 2],\n",
    "        [2, 2, 0, 0],\n",
    "        [0, 2, 1, 0],\n",
    "        [2, 2, 0, 2],\n",
    "        [1, 2, 0, 2],\n",
    "        [0, 2, 2, 2],\n",
    "        [0, 2, 1, 2],\n",
    "        [2, 2, 2, 0],\n",
    "        [1, 2, 1, 0],\n",
    "    ]\n",
    ")\n",
    "# We can now create a list of factors with the correct neighbors and valid configurations\n",
    "factors_list = suppression_factors_list\n",
    "for fac_name in factors_dict.keys():\n",
    "    curr_fac = factors_dict[fac_name]\n",
    "    curr_fac.set_neighbors(factors_neighbors_dict[fac_name])\n",
    "    curr_fac.set_valid_configs(valid_configs)\n",
    "    factors_list.append(curr_fac)\n",
    "\n",
    "# Now that we have all the necessary nodes and edges, instantiate the node_classes.FactorGraph:\n",
    "fg = node_classes.FactorGraph(\"cuts_fg\", factors_list, vars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_has_cuts = gt_has_cuts.astype(np.int32)\n",
    "\n",
    "# First, we create an array such that the [0,i,j] entry corresponds to the  horizontal cut variable that's at that location in the\n",
    "# image, and the [1,i,j] entry corresponds to the  vertical cut variable that's at that location\n",
    "var_img_arr = np.array([[[None] * M] * N] * 2)\n",
    "    \n",
    "# We then loop thru and generate all rows and column variables\n",
    "for row in range(M - 1):\n",
    "    for col in range(N - 1):\n",
    "        if row == 0:\n",
    "            var_img_arr[1, 0, col] = vars_dict[f\"V0,{col},up\"]\n",
    "        var_img_arr[1, row + 1, col] = vars_dict[f\"V{row},{col},down\"]\n",
    "        if col == 0:\n",
    "            var_img_arr[0, row, 0] = vars_dict[f\"V{row},0,left\"]\n",
    "        var_img_arr[0, row, col+1] = vars_dict[f\"V{row},{col},right\"]\n",
    "\n",
    "# Now, we use this array along with the gt_has_cuts array computed earlier using the image in order to derive the evidence values\n",
    "var_evidence_dict = {}\n",
    "for i in range(2):\n",
    "    for row in range(M):\n",
    "        for col in range(N):\n",
    "            # The dictionary key is in var_img_arr at loc [i,row,call] (the VariableNode is stored here!)\n",
    "            evidence_arr = np.zeros(\n",
    "                3\n",
    "            )  # Note that we know num states for each variable is 3, so we can do this\n",
    "            evidence_arr[\n",
    "                gt_has_cuts[i, row, col]\n",
    "            ] = 2.0  # This assigns belief value 2.0 to the correct index in the evidence vector\n",
    "            evidence_arr = evidence_arr - evidence_arr[0] # This normalizes the evidence by subtracting away the 0th index value\n",
    "            evidence_arr[1:] += 0.1 * rng.logistic(size=evidence_arr[1:].shape) # This adds logistic noise for every evidence entry\n",
    "            if var_img_arr[i, row, col] is not None:\n",
    "                var_evidence_dict[var_img_arr[i, row, col]] = evidence_arr"
   ]
  },
  {
   "source": [
    "## Belief Propagation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run MAP inference to get the MAP estimate of each variable\n",
    "map_message_dict = mp_belief_prop_jax_orig.run_mp_belief_prop_and_compute_map(fg, var_evidence_dict, 1000, 0.5)\n"
   ]
  },
  {
   "source": [
    "## Visualization of Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Place the variable values derived from BP onto an image-sized array so they can be visualized. Do the same for bottom-up evidences that are just GT + logistic noise\n",
    "bp_values = np.zeros((2,M,N))\n",
    "bu_evidence = np.zeros((2,M,N,3))\n",
    "for i in range(2):\n",
    "    for row in range(M):\n",
    "        for col in range(N):\n",
    "            if var_img_arr[i,row,col] is not None:\n",
    "                bp_values[i,row,col] = map_message_dict[var_img_arr[i,row,col]]\n",
    "                bu_evidence[i,row,col,:] = var_evidence_dict[var_img_arr[i,row,col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function for viz\n",
    "def get_color_mask(image, nc=None):\n",
    "    image = image.astype(int)\n",
    "    n_colors = image.max() + 1\n",
    "\n",
    "    cm = plt.get_cmap('gist_rainbow')\n",
    "    colors = [cm(1.0 * i / n_colors) for i in np.random.permutation(n_colors)]\n",
    "\n",
    "    color_mask = np.zeros(image.shape + (3,)).astype(np.uint8)\n",
    "    for i in np.unique(image):\n",
    "        color_mask[image == i, :] = np.array(colors[i][:3]) * 255\n",
    "    return color_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surface_labels_from_cuts(has_cuts):\n",
    "    \"\"\"get_surface_labels_from_cuts\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    has_cuts : np.array\n",
    "        Array of shape (2, M, N)\n",
    "    Returns\n",
    "    -------\n",
    "    surface_labels : np.array\n",
    "        Array of shape (M, N)\n",
    "        Surface labels of each pixel\n",
    "    \"\"\"\n",
    "    M, N = has_cuts.shape[1:]\n",
    "    # Indices for 4-connected grid\n",
    "    nodes_indices0 = (np.arange(1, M) - 1)[:, None] * N + np.arange(N)\n",
    "    nodes_indices1 = (np.arange(M - 1) + 1)[:, None] * N + np.arange(N)\n",
    "    nodes_indices2 = np.arange(M)[:, None] * N + np.arange(1, N) - 1\n",
    "    nodes_indices3 = np.arange(M)[:, None] * N + np.arange(N - 1) + 1\n",
    "    row_indices_for_grid = np.concatenate(\n",
    "        [nodes_indices0.ravel(), nodes_indices2.ravel()]\n",
    "    )\n",
    "    col_indices_for_grid = np.concatenate(\n",
    "        [nodes_indices1.ravel(), nodes_indices3.ravel()]\n",
    "    )\n",
    "    # Indices for cuts\n",
    "    horizontal_row_indices_for_cuts, horizontal_col_indices_for_cuts = np.nonzero(\n",
    "        has_cuts[0, :-1]\n",
    "    )\n",
    "    vertical_row_indices_for_cuts, vertical_col_indices_for_cuts = np.nonzero(\n",
    "        has_cuts[1, :, :-1]\n",
    "    )\n",
    "    row_indices_for_cuts = np.concatenate(\n",
    "        [\n",
    "            horizontal_row_indices_for_cuts * N + horizontal_col_indices_for_cuts,\n",
    "            vertical_row_indices_for_cuts * N + vertical_col_indices_for_cuts,\n",
    "        ]\n",
    "    )\n",
    "    col_indices_for_cuts = np.concatenate(\n",
    "        [\n",
    "            (horizontal_row_indices_for_cuts + 1) * N + horizontal_col_indices_for_cuts,\n",
    "            vertical_row_indices_for_cuts * N + (vertical_col_indices_for_cuts + 1),\n",
    "        ]\n",
    "    )\n",
    "    csgraph = sparse.lil_matrix((M * N, M * N), dtype=np.int32)\n",
    "    csgraph[row_indices_for_grid, col_indices_for_grid] = 1\n",
    "    csgraph[col_indices_for_grid, row_indices_for_grid] = 1\n",
    "    csgraph[row_indices_for_cuts, col_indices_for_cuts] = 0\n",
    "    csgraph[col_indices_for_cuts, row_indices_for_cuts] = 0\n",
    "    n_connected_components, surface_labels = sparse.csgraph.connected_components(\n",
    "        csgraph.tocsr(), directed=False, return_labels=True\n",
    "    )\n",
    "    surface_labels = np.random.permutation(n_connected_components)[\n",
    "        surface_labels.reshape((M, N))\n",
    "    ]\n",
    "    return surface_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth cuts\n",
    "gt_cuts_img = np.zeros((2 * M, 2 * N))\n",
    "gt_cuts_img[\n",
    "    np.arange(1, 2 * M, 2).reshape((-1, 1)), np.arange(0, 2 * N, 2).reshape((1, -1))\n",
    "] = gt_has_cuts[0]\n",
    "gt_cuts_img[\n",
    "    np.arange(0, 2 * M, 2).reshape((-1, 1)), np.arange(1, 2 * N, 2).reshape((1, -1))\n",
    "] = gt_has_cuts[1]\n",
    "\n",
    "# Bottom-up evidences for cuts\n",
    "bu_has_cuts = np.argmax(bu_evidence, axis=-1)\n",
    "bu_cuts_img = np.zeros((2 * M, 2 * N))\n",
    "bu_cuts_img[\n",
    "    np.arange(1, (2 * M), 2).reshape((-1, 1)), np.arange(0, (2 * N), 2).reshape((1, -1))\n",
    "] = bu_has_cuts[0]\n",
    "bu_cuts_img[\n",
    "    np.arange(0, (2 * M), 2).reshape((-1, 1)), np.arange(1, (2 * N), 2).reshape((1, -1))\n",
    "] = bu_has_cuts[1]\n",
    "\n",
    "# Predicted cuts\n",
    "cuts_img = np.zeros((2 * M, 2 * N))\n",
    "cuts_img[\n",
    "    np.arange(1, 2 * M, 2).reshape((-1, 1)), np.arange(0, 2 * N, 2).reshape((1, -1))\n",
    "] = bp_values[0]\n",
    "cuts_img[\n",
    "    np.arange(0, 2 * M, 2).reshape((-1, 1)), np.arange(1, 2 * N, 2).reshape((1, -1))\n",
    "] = bp_values[1]\n",
    "\n",
    "# Plot ground-truth cuts\n",
    "fig, ax = plt.subplots(2, 3, figsize=(30, 20))\n",
    "ax[0, 0].imshow(gt_cuts_img)\n",
    "ax[0, 0].set_title('Ground truth', fontsize=40)\n",
    "ax[0, 0].axis('off')\n",
    "ax[1, 0].imshow(get_color_mask(labels_img))\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "# Plot bottom-up evidences for cuts\n",
    "ax[0, 1].imshow(bu_cuts_img)\n",
    "ax[0, 1].axis('off')\n",
    "ax[0, 1].set_title('Using bottom-up evidences', fontsize=40)\n",
    "ax[1, 1].imshow(\n",
    "    get_color_mask(get_surface_labels_from_cuts(bu_has_cuts > 0))\n",
    ")\n",
    "ax[1, 1].axis('off')\n",
    "\n",
    "# Plot predicted cuts\n",
    "ax[0, 2].imshow(cuts_img)\n",
    "ax[0, 2].axis('off')\n",
    "ax[0, 2].set_title('Using surface model', fontsize=40)\n",
    "ax[1, 2].imshow(get_color_mask(get_surface_labels_from_cuts(bp_values > 0)))\n",
    "ax[1, 2].axis('off')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pgmax-JcKb81GE-py3.8': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "194dee81edac360c81a4f5140309dc9d8c71281a628dab44a3eea4b4df29b300"
   }
  },
  "interpreter": {
   "hash": "194dee81edac360c81a4f5140309dc9d8c71281a628dab44a3eea4b4df29b300"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}